---
title: 'Lending Case'
author: "Adrian Garces"
date: "2025-05-01"
output: html_document
---
1a. Your team’s goal is to help clients determine whether and which p2p loans to invest in. What is the specific decision task or tasks that you will address? How will you evaluate ‘better’ vs ‘worse’ decisions? What will be the potential target variable(s)? 
```{r}
library(dplyr)
lcdf = read.csv("lcdfSample.csv")
lcdf$loan_status # this is the target variable for this problem

```
1b. Take a look at the data attributes. Categorize these attributes considering what they pertain to. Before conducting any analyses, which attributes do you think may important to consider for your decision task? 
```{r}
str(lcdf)
glimpse(lcdf)
summary(lcdf)
# columns with the most missing values 
missing_count = sort(colSums(is.na(lcdf)), decreasing = TRUE)
total_row = nrow(lcdf)
missing_row_count = sum(missing_count > (0.5*total_row))
missing_row_count # there are 57 rows with more than 50% of their values missing 
```

2ai. What is the proportion of defaults (‘charged off’ vs ‘fully paid’ loans) in the data? How does default rate vary with loan grade? Does it vary with sub-grade? Do you think loan grade and sub-grade convey useful information on riskiness of different loans? 
```{r}
# just the loans and propotions 
lcdf %>% group_by(loan_status) %>% 
    summarise(n=n()) %>% 
    mutate(proportion=n/sum(n))

# loans with loan grades
lcdf %>% group_by(loan_status, grade) %>% 
    summarise(n=n()) %>%
    arrange(desc(n), by_group = T)

# loans with subgrades
lcdf %>% group_by(loan_status, sub_grade) %>% 
    summarise(n=n()) %>%
    arrange(desc(n), by_group = T)
```

2a ii . How many loans are there in each grade? Do loan amounts vary by grade? And how does this vary by loan status? Provide suitable plots to show this and summarize your conclusions.

```{r}
# loan amount by grade 
lcdf %>% group_by(grade) %>% 
    summarise(sum(loan_amnt))

total_loan = sum(lcdf$loan_amnt)

# loan amount by status 
loan_grade_summary = lcdf %>%
  group_by(grade) %>%  # Group by grade
  summarise(sum_loan = sum(loan_amnt)) %>% 
    arrange(desc(sum_loan)) %>%
  mutate(proportion= round(sum_loan/total_loan*100))

loan_grade_summary


# barplot for the grades and the difference in amount from the previous grade arranged by alphabetical order


barplot(loan_grade_summary$proportion, 
        names.arg = loan_grade_summary$grade, 
        main = "Proportion of Loan Amount Per Grade", 
        xlab = "Grade", 
        ylab = "Loan Amount Proportion (%) ",
        col = "green",
        border = "black")



```
2a iii Does interest rate for loans vary by grade, subgrade? Look at the average, standard- deviation, min and max of interest rate by grade and subgrade. Is this what you expect, and why? 

```{r}
# for grades
lcdf %>%
  group_by(grade) %>%  # Group by grade
  summarise(
      Avg = mean(int_rate),
      Max = max(int_rate),
      Min = min(int_rate),
      Std = sd(int_rate)
  )

# for subgrades
int_rate_subgrades = lcdf %>%
  group_by(sub_grade) %>%  # Group by subgrade
  summarise(
      Avg = mean(int_rate),
      Max = max(int_rate),
      Min = min(int_rate),
      Std = sd(int_rate)
  )
barplot(loan_grade_summary$proportion, 
        names.arg = loan_grade_summary$grade, 
        main = "Proportion of Loan Amount Per Grade", 
        xlab = "Grade", 
        ylab = "Loan Amount Proportion (%) ",
        col = "green",
        border = "black")
```
2a iv. Does int_rate relate with loan status? What do you conclude? (Note that the interest rate is set before a loan is made, and the status is known later). And does this vary by grade?

```{r}
ggplot(lcdf, aes(x= loan_status, y = int_rate)) +
    geom_boxplot( fill = "slateblue", alpha = 0.2) 

ggplot(lcdf, aes(x= grade, y = int_rate)) +
    geom_boxplot( fill = "slateblue", alpha = 0.2) 
```
Annual Rate 
```{r}

#do loans return an amount as may be expected from the int_rate ? 
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt) %>% head()


#calculate the annualized percentage return
lcdf$annRet <- ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100

#summarize by grade
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet), stdRet=sd(annRet), minRet=min(annRet), maxRet=max(annRet))

#Where do the negative numbers for minRet come from?
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>% filter(annRet < 0) %>% head()

#are these all from 'Charged Off' loans?
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>% filter(annRet < 0) %>% count(loan_status)

#Returns from 'Fully Paid' loans
lcdf %>% filter( loan_status == "Fully Paid") %>% group_by(grade) %>% summarise(nLoans=n(),  avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet),  minRet=min(annRet), maxRet=max(annRet))


#Similarly, returns from 'Charged Off" loans
lcdf %>% filter( loan_status == "Charged Off") %>% group_by(grade) %>% summarise(nLoans=n(), avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet),  minRet=min(annRet), maxRet=max(annRet))


```
2a v. For loans which are fully paid back, how does the time-to-full-payoff vary? For this, calculate the ‘actual term’ (issue-date to last-payment-date) for all loans. How does this actual-term vary by loan grade (a box-plot can help visualize this) 

```{r}
lcdf1 = read.csv("lcdfSample.csv")

head(lcdf1[, c("last_pymnt_d", "issue_d")])

library(lubridate)

lcdf1$last_pymnt_d = paste(lcdf1$last_pymnt_d, "-01", sep = "")
lcdf1$last_pymnt_d = parse_date_time(lcdf1$last_pymnt_d, "myd")

lcdf1$actualTerm = ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf1$issue_d  %--% lcdf1$last_pymnt_d)/dyears(1), 3)

boxplot(lcdf1$actualTerm)
```


2 vi. Calculate the annual return for a loan. Explain how you calculate the percentage annual return. 

```{r}
lcdf1$actualReturn <- ifelse(lcdf1$actualTerm>0, ((lcdf1$total_pymnt -lcdf1$funded_amnt)/lcdf1$funded_amnt)*(1/lcdf1$actualTerm)*100, 0)

lcdf1$annRet <- ((lcdf1$total_pymnt -lcdf1$funded_amnt)/lcdf1$funded_amnt)*(12/36)*100

lcdf1 %>% 
    select(loan_status, int_rate, funded_amnt, total_pymnt, annRet, actualTerm, actualReturn) %>% 
    head()

```
2 vi For ‘charged off’ loans, will investors lose all their investment? Explain. Examine whether return from charged -off loans vary by loan grade and explain what you find. Compare the average return values with the average interest-rate on loans – do you notice any differences, and how do you explain this? How do returns vary by grade, and by sub-grade. If you decide to invest in loans based on this data exploration, which loans would you prefer to invest in? 

```{r}

# Filter for charged-off loans and calculate the difference
charged_off_data <- lcdf1 %>%
  filter(loan_status == "Charged Off") %>%
  mutate(difference = funded_amnt - total_pymnt)  # Loss amount

# Summarize the average difference by loan grade
Charged_Off_Summary_Table <- charged_off_data %>%
  group_by(grade) %>%
  summarise(
    avg_loss = mean(difference, na.rm = TRUE),  # Average loss per grade
    median_loss = median(difference, na.rm = TRUE),
    AvgInt = mean(int_rate),
    AvgReturn = mean(actualReturn),
    total_loss = sum(difference, na.rm = TRUE),
    count = n()
  ) %>%
  arrange(desc(avg_loss))

#subgrade
Sub_Charged_Off_Summary_Table <- charged_off_data %>%
  group_by(sub_grade) %>%
  summarise(
    avg_loss = mean(difference, na.rm = TRUE),  # Average loss per grade
    median_loss = median(difference, na.rm = TRUE),
    AvgInt = mean(int_rate),
    AvgReturn = mean(actualReturn),
    total_loss = sum(difference, na.rm = TRUE),
    count = n()
  ) %>%
  arrange(desc(avg_loss))

Sub_Charged_Off_Summary_Table
```
3. Do a univariate analysis to determine which variables (from amongst those you decide to consider for the next stage prediction task) will be individually useful for predicting the dependent variable (loan_status). For this, you need a measure of the relationship between the dependent variable and each of the potential predictor variables. Given loan-status as a binary dependent variable, which measure will you use? From your analyses using this measure, which variables do you think will be useful for predicting loan_status? (Note – if certain variables on their own are highly predictive of the outcome, it is good to ask if this variable has a leakage issue). 

```{r}
# this is checking with columns have only missing values, these will be removed. 
lcdf1 %>% select_if( function(x) { all(is.na(x)) } ) %>% colnames() 

#Drop vars with all empty values # after we do this we are down to 112 variables.
lcdf1 <- lcdf1 %>% select_if(function(x){ ! all(is.na(x)) } )

# let's see the proportations of missing values within a dataset 

missing_info = data.frame(
    variable = character(),
    missing_ratio = numeric(),
    stringsAsFactors = FALSE
)

for (col_name in names(lcdf1)) {
    na_count = sum(is.na(lcdf1[[col_name]]))
    na_ratio = round(na_count/nrow(lcdf1),2)
    missing_info = rbind(
        missing_info,
        data.frame( variable = col_name, missing_ratio = na_ratio, stringsAsFactors = FALSE)
    )
}

missing_info2 = missing_info[order(-missing_info$missing_ratio), ]

missing_info# this shows the varibales and their missing ratio


# this shows the names of the variables with missing rations higher than 0.6, we are removing them
cols_to_remove <- missing_info$variable[missing_info$missing_ratio > 0.49] 

# we are removing the names extracted from the cols_to_remove, if the name appears in both datasets 
# the column will be removed.
lcdf2 <- lcdf1[, !(names(lcdf1) %in% cols_to_remove)]

# new structure
str(lcdf1)


fill_missing_values <- function(df) {
  for (col_name in names(df)) {
    # If this column contains any missing values, proceed
    if (anyNA(df[[col_name]])) {

      # Check the column type
      if (is.numeric(df[[col_name]])) {
        # 1. For numeric columns: fill with the median
        median_val <- median(df[[col_name]], na.rm = TRUE)
        df[[col_name]][is.na(df[[col_name]])] <- median_val

      } else if (is.character(df[[col_name]])) {
        # 2. For character columns: fill with "missing"
        df[[col_name]][is.na(df[[col_name]])] <- "missing"

      } else if (is.logical(df[[col_name]])) {
        # 3. For logical columns: fill with the majority value (TRUE or FALSE)
        count_true <- sum(df[[col_name]] == TRUE, na.rm = TRUE)
        count_false <- sum(df[[col_name]] == FALSE, na.rm = TRUE)

        if (count_true >= count_false) {
          df[[col_name]][is.na(df[[col_name]])] <- TRUE
        } else {
          df[[col_name]][is.na(df[[col_name]])] <- FALSE
        }
      }
    }
  }
  return(df)
}


fill_missing_values(lcdf1)
na.omit(lcdf1)

library(pROC) #this package has a function auc(..) which we can readily use

#We will use the function auc(response, prediction) which returns the AUC value for the specified predictor variable, and considering the response variable as the dependent. 
#   Make sure you understand how this works.

# For example:
auc(response=lcdf$loan_status, lcdf$loan_amnt)
 # returns the auc value for loan_amt as the single predictor for loan_status

# this is applying the AUC fuction to all the numeric values within the lcdf1 dataset 
aucsNum<-sapply(lcdf1 %>% select_if(is.numeric), auc, response=lcdf1$loan_status)

aucAll<- sapply(lcdf1 %>% 
                    mutate_if(is.factor, as.numeric) %>%
                    select_if(is.numeric), auc, response=lcdf1$loan_status) 
aucAll[aucAll>0.5]

library(broom)

# this displays the AUC values that are over 0.5 in a neater format
tidy(aucAll[aucAll > 0.5]) %>% 
View()

# or  in any range of values like, tidy(aucAll[aucAll >=0.5 & aucAll < 0.6])
# or in sorted order
tidy(aucAll) %>% 
    arrange(desc(aucAll)) %>%
    View()

```
4. Split the data into trn, text subsets
```{r}
lcdf2 = read.csv("lcdf2.csv")

TRNPROP = 0.7  #proportion of examples in the training sample

nr<-nrow(lcdf2)
trnIndex<- sample(1:nr, size = round(TRNPROP * nr), replace=FALSE)

lcdfTrn <- lcdf2[trnIndex, ]
lcdfTst <- lcdf2[-trnIndex, ]

```
5. Develop a decision tree model to predict default. Train decision tree models (use either rpart or c50) 
What parameters do you experiment with, and what performance do you obtain (on training and validation sets)? Clearly tabulate your results and describe your findings. [If something looks too good, it may be due to leakage – make sure you address this] Identify the best tree model. Why do you consider it best? 
Describe this model – in terms of complexity (size). Examine variable importance. How does this relate to your uni-variate analyses in Question 3 above? 

```{r}
#Do you want to use all the variables in the dataset as predictors ?
#Take a look at teh data
glimpse(lcdf2)

#Are are some variable you want to exclude  - due to leakage, or other reasons?
#  What about variables like actualTerm, actualReturn, ... which you calculated?
#       These will be useful in performance assessment, but should not be used in building the model.
#Are there any data variables which you may not want to use in developing the model?

#omitting certain variables for this model
varsOmit <- c(
  'actualTerm', 'actualReturn', 'annRet', 'total_pymnt', 'open_acc', 'num_sats', 
  'num_rev_accts', 'installment', 'X', 'out_prncp', 
  'out_prncp_inv', 'policy_code', 'num_tl_120dpd_2m', 'delinq_amnt', 
  'chargeoff_within_12_mths', 'num_tl_30dpd', 'acc_now_delinq', 'tax_liens', 
  'collections_12_mths_ex_med', 'num_bc_sats', 'num_tl_90g_dpd_24m', 
  'delinq_2yrs', 'pub_rec_bankruptcies', 'tot_coll_amt', 'num_accts_ever_120_pd', 
  'pub_rec', 'num_actv_bc_tl', 'num_rev_tl_bal_gt_0', 'num_actv_rev_tl', 
  'percent_bc_gt_75', 'total_rec_late_fee', 'num_il_tl', 'total_il_high_credit_limit', 
  'pct_tl_nvr_dlq', 'num_bc_tl', 'total_bal_ex_mort', 'num_op_rev_tl','total_rec_prncp','total_rec_prncp', 'collection_recovery_fee','debt_settlement_flag','recoveries','emp_title','title','zip_code','earliest_cr_line','last_credit_pull_d'
)





library(rpart)
# converting loan_status from character to factor
lcdf2$loan_status <- factor(lcdf2$loan_status, levels=c("Fully Paid", "Charged Off"))

# creating the model. this is after we took out variables that may cause data leakage
lcDT1a <- rpart(loan_status ~., data=lcdfTrn %>% select(-all_of(varsOmit)), method="class", parms = list(split = "information"), control = rpart.control(minsplit = 30))

printcp(lcDT1a)


lcDT1$variable.importance

# new variable importance after taking out the old variable s
lcDT1a$variable.importance

# Changing model parameters
lcDT1b <- rpart(loan_status ~., data=lcdfTrn %>% select(-all_of(varsOmit)), method="class", parms = list(split = "information"), control = rpart.control(cp=0.0001, minsplit = 50))

printcp(lcDT1b)

#let's prune the tree
lcDT1bp<- prune.rpart(lcDT1b, cp=0.0003) 
printcp(lcDT1bp)

# 4th model
lcDT1c <- rpart(loan_status ~., data=lcdfTrn %>% select(-all_of(varsOmit)), 
               method="class", parms = list(split = "gini", prior=c(0.5, 0.5)), 
               control = rpart.control(cp=0.0, minsplit = 20, minbucket = 10, maxdepth = 20,  xval=10) )

printcp(lcDT1c)

lcDT1c$variable.importance

mincp_i <- which.min(lcDT1c$cptable[, 'xerror']) #the row (index) corresponding to the min xerror
optError <- lcDT1c$cptable[mincp_i, "xerror"] + lcDT1c$cptable[mincp_i, "xstd"]
optCP_i <- which.min(abs( lcDT1c$cptable[,"xerror"] - optError))
optCP <- lcDT1c$cptable[optCP_i, "CP"]

lcDT1c<- prune.rpart(lcDT1c, cp=optCP)

printcp(lcDT1c)

```
4. Evaluation of the Model 
```{r}
predTrn = predict(lcDT1c, lcdfTrn, type = 'class')
table(prediction = predTrn, True = lcdfTrn$loan_status)
mean(predTrn == lcdfTrn$loan_status) # this is calculating the accuracy 


# Now we will be using the testing data
predTest = predict(lcDT1c, lcdfTst, type = 'class')
table(prediction = predTest, True = lcdfTst$loan_status)
mean(predTest == lcdfTst$loan_status)

library(ROCR)
score=predict(lcDT1c,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf) # Plot the ROC curve first
abline(a=0, b=1, col="red", lty=2)  

aucPerf=performance(pred, "auc")
aucPerf@y.values

liftPerf <-performance(pred, "lift", "rpp")
plot(liftPerf)

```

5f. Creating a random Forrest Tree 

```{r}
library(ranger)
lcdfTrn$loan_status <- as.factor(lcdfTrn$loan_status)

rfModel1 <- ranger(loan_status ~., data=lcdfTrn %>%  select(-all_of(varsOmit)), num.trees = 200, importance='permutation', probability = TRUE)

vimp_rfGp<-importance(rfModel1)
vimp_rfGp %>% View()

#Get the predictions -- look into the returned object
scoreTrn <- predict(rfModel1,lcdfTrn)
head(scoreTrn$predictions)

#classification performance , at specific threshold 
table(Pred = scoreTrn$predictions[, "Fully Paid"] > 0.7, Actuals =lcdfTrn$loan_status)


(60292+3723)/(60292+3723+16) # this the accuracy of the training data on the rf model 

scoreTst_RF_Class <- predict(rfModel1,lcdfTst)
table(pred = scoreTst$predictions[, "Fully Paid"] > 0.7, actual=lcdfTst$loan_status)
(25545+3723)/(25545+3723+328+392)*100

#random forrest number 2 
rfModel2 <- ranger(loan_status ~., data=lcdfTrn %>%  select(-all_of(varsOmit)),
                   num.trees =500, probability = TRUE, min.node.size = 50, max.depth = 15)

```

ROC Curve and AUC for RF Model 1 
```{r}
#ROC curve, AUC
pred=prediction(scoreTrn$predictions[, "Fully Paid"], lcdfTrn$loan_status, label.ordering = c("Charged Off","Fully Paid" ))  #ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
sprintf("AUC: %f", aucPerf@y.values)
#AUC value
aucPerf=performance(pred, "auc")
sprintf("AUC: %f", aucPerf@y.values)

#Testing Data ROC Curve 
pred=prediction(scoreTst$predictions[, "Fully Paid"], lcdfTst$loan_status, label.ordering = c("Charged Off","Fully Paid" ))  #ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
sprintf("AUC: %f", aucPerf@y.values)

#Lift curve
liftPerf <-performance(pred, "lift", "rpp")
plot(liftPerf)

```


Random Forest Model for Returns
```{r}
nDecileLiftsPerformance_defaults  <- function( scores, dat) {  #score is for loan_status=='Charged Off'
  totDefRate= sum(dat$loan_status=="Charged Off")/nrow(dat)
  decPerf <- data.frame(scores)
  decPerf <- cbind(decPerf, status=dat$loan_status, grade=dat$grade)
  decPerf <- decPerf %>% mutate(decile = ntile(-scores, 10))
  decPerf<-  decPerf  %>% group_by(decile) %>% summarise ( 
    count=n(), numDefaults=sum(status=="Charged Off"), defaultRate=numDefaults/count,
    totA=sum(grade=="A"),totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"),
    totE=sum(grade=="E"),totF=sum(grade=="F") )
  decPerf$cumDefaults=cumsum(decPerf$numDefaults)                      
  decPerf$cumDefaultRate=decPerf$cumDefaults/cumsum(decPerf$count)                      
  decPerf$cumDefaultLift<- decPerf$cumDefaultRate/(sum(decPerf$numDefaults)/sum(decPerf$count))
  
  print(decPerf)
}


#Returns performance by deciles
fnDecileReturnsPerformance <- function( scores, dat) {
  decRetPerf <- data.frame(scores)
  decRetPerf <- cbind(decRetPerf, status=dat$loan_status, grade=dat$grade, actRet=dat$actualReturn, actTerm = dat$actualTerm)
  decRetPerf <- decRetPerf %>% mutate(decile = ntile(-scores, 10))
  decRetPerf %>% group_by(decile) %>% summarise (
    count=n(), numDefaults=sum(status=="Charged Off"), avgActRet=mean(actRet), minRet=min(actRet), maxRet=max(actRet),
    avgTer=mean(actTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"),
    totE=sum(grade=="E"), totF=sum(grade=="F") )
}

fnDecileReturnsPerformance ( predict(rfModel2, lcdfTrn)$predictions[,"Fully Paid"], lcdfTrn )




```


Actual Returns Data on the testing set first 
```{r}

library(ranger)
library(dplyr)
rfModel_Ret <- ranger(actualReturn ~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees =200,
importance='permutation')
rfPredRet_trn <- predict(rfModel_Ret, lcdfTrn)
sqrt( mean( (rfPredRet_trn$predictions - lcdfTrn$actualReturn)^2) )
#sqrt(mean( ( (predict(rfModel_Ret, lcdfTst))$predictions - lcdfTst$actualReturn)^2))
plot ( (predict(rfModel_Ret, lcdfTrn))$predictions, lcdfTrn$actualReturn)
plot ( (predict(rfModel_Ret, lcdfTst))$predictions, lcdfTst$actualReturn)


# performance by decile on the training data 

predRet_Trn <- lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
mutate(predRet=(predict(rfModel_Ret, lcdfTrn))$predictions)

predRet_Trn <- predRet_Trn %>% mutate(tile=ntile(-predRet, 10))

PerfByDecileRFActualReturns = predRet_Trn %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

View(PerfByDecileRFActualReturns)
```

RF Model now comparing on testing data 
```{r}
rfPredRet_tst <- predict(rfModel_Ret, lcdfTst)

# Get predicted returns for testing data
predRet_Tst <- lcdfTst %>%
  select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
  mutate(predRet = (predict(rfModel_Ret, lcdfTst))$predictions)

# Assign decile based on predicted return (higher returns = top decile)
predRet_Tst <- predRet_Tst %>%
  mutate(tile = ntile(-predRet, 10))

# Summarize performance by decile on test data
PerfByDecileRFActualReturns_Tst <- predRet_Tst %>%
  group_by(tile) %>%
  summarise(
    count = n(),
    avgpredRet = mean(predRet),
    numDefaults = sum(loan_status == "Charged Off"),
    avgActRet = mean(actualReturn),
    minRet = min(actualReturn),
    maxRet = max(actualReturn),
    avgTer = mean(actualTerm),
    totA = sum(grade == "A"),
    totB = sum(grade == "B"),
    totC = sum(grade == "C"),
    totD = sum(grade == "D"),
    totE = sum(grade == "E"),
    totF = sum(grade == "F")
  )
View(PerfByDecileRFActualReturns_Tst)


```
Creating a linear model 
```{r}

set.seed(42)
library(dplyr)
#check which columns have missing values
colMeans(is.na(lcdf2))[colMeans(is.na(lcdf2))>0]

lcdf_noMiss <- lcdf2 %>% mutate(across(where(is.numeric), ~replace_na(., median(., na.rm=TRUE))))
library(tidyr)

#Check to make sure there are no missings remaining
colMeans(is.na(lcdf_noMiss))[colMeans(is.na(lcdf_noMiss))>0]

#Train.,Test samples after imputing missing values
lcdfTrn <- lcdf_noMiss[trnIndex, ]
lcdfTst<- lcdf_noMiss[-trnIndex, ]

#for a factor dependent var, the second level in alphabetic order is taken as the '1' (target)
#We can specifically encode the dependent var here to make sure that 1 is for "Fully Paid"
levels(lcdfTrn$loan_status)
yTrn<-factor(if_else(lcdfTrn$loan_status=="Fully Paid", '1', '0') )

xDTrn <- lcdfTrn %>%
  select(-loan_status, -actualTerm, -annRet, -actualReturn, 
         -total_pymnt,-emp_title,-title,-last_pymnt_d,-last_credit_pull_d)

xdTest = lcdfTst %>%
  select(-loan_status, -actualTerm, -annRet, -actualReturn, 
         -total_pymnt,-emp_title,-title,-last_pymnt_d,-last_credit_pull_d)

library(glmnet)


# model that I am using for this portion
glmRet_cv_a2<- cv.glmnet(data.matrix(xDTrn), lcdfTrn$actualReturn, family="gaussian", alpha=0.2)


glmRet_cv_a2PredictionsTraining=predict( glmRet_cv_a2, s="lambda.min", newx = (data.matrix(xDTrn)))
                                                                               
glmRet_cv_a2PredictionsTest=predict(glmRet_cv_a2, s="lambda.min", newx = (data.matrix(xdTest)))

# here we are plotting the two training and testing data against the actual returns                                                                               
plot (glmRet_cv_a2PredictionsTraining, lcdfTrn$actualReturn)
plot (glmRet_cv_a2PredictionsTest, lcdfTst$actualReturn)
                                         

#creating the charts 
predRet_Tst_linear_model <- lcdfTst %>%
  select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
  mutate(predRet = glmRet_cv_a2PredictionsTest)

predRet_Tst_linear_model <- predRet_Tst_linear_model %>%
  mutate(tile = ntile(-predRet, 10))

Decile_Returns_Test_LM <- predRet_Tst_linear_model %>%
  group_by(tile) %>%
  summarise(
    count = n(),
    avgpredRet = mean(predRet),
    numDefaults = sum(loan_status == "Charged Off"),
    avgActRet = mean(actualReturn),
    minRet = min(actualReturn),
    maxRet = max(actualReturn),
    avgTer = mean(actualTerm),
    totA = sum(grade == "A"),
    totB = sum(grade == "B"),
    totC = sum(grade == "C"),
    totD = sum(grade == "D"),
    totE = sum(grade == "E"),
    totF = sum(grade == "F")
  )

Decile_Returns_Test_LM
```


9b. Comparing Models 
```{r}
Decile_Returns_Test_LM
PerfByDecileRFActualReturns_Tst

sqrt( mean((glmRet_cv_a2PredictionsTest - lcdfTst$actualReturn)^2) ) # MSE for the testing set for LM
sqrt( mean( (rfPredRet_tst$predictions - lcdfTst$actualReturn)^2) )
```


 10a. Lower Grade Loans with Regularized Regression Model 
```{r}
lowGradeLoans <- lcdf_noMiss %>% filter(grade %in% c("C", "D", "E", "F", "G"))

TRNPROP = 0.7  #proportion of examples in the training sample

nr<-nrow(lowGradeLoans)
trnIndex<- sample(1:nr, size = round(TRNPROP * nr), replace=FALSE)

lcdfTrn <- lowGradeLoans[trnIndex, ]
lcdfTst <- lowGradeLoans[-trnIndex, ]



xDTrn <- lcdfTrn %>%
  select(-loan_status, -actualTerm, -annRet, -actualReturn, 
         -total_pymnt,-emp_title,-title,-last_pymnt_d,-last_credit_pull_d,revol_util)

xdTest = lcdfTst %>%
  select(-loan_status, -actualTerm, -annRet, -actualReturn, 
         -total_pymnt,-emp_title,-title,-last_pymnt_d,-last_credit_pull_d,revol_util)

# model that I am using for this portion
glm_lower_grade<- cv.glmnet(data.matrix(xDTrn), lcdfTrn$actualReturn, family="gaussian", alpha=0.8)


glm_lower_grade_training=predict( glm_lower_grade, s="lambda.min", newx = (data.matrix(xDTrn)))
                                                                               
glm_lower_grade_testing=predict(glm_lower_grade, s="lambda.min", newx = (data.matrix(xdTest)))

sqrt( mean((glm_lower_grade_testing - lcdfTst$actualReturn)^2) ) 


predRet_Tst_linear_mode_lower_grades <- lcdfTst %>%
  select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
  mutate(predRet = glm_lower_grade_testing,
         tile = ntile(-predRet, 10))



predRet_Tst_linear_mode_lower_grades_outcome <- predRet_Tst_linear_mode_lower_grades %>%
  group_by(grade) %>%
  summarise(
    count = n(),
    avgpredRet = mean(predRet),
    numPaidOff = sum(loan_status == "Fully Paid"),
    numDefalted = sum(loan_status == "Charged Off"),
    avgActRet = mean(actualReturn),
    minRet = min(actualReturn),
    maxRet = max(actualReturn),
    avgTer = mean(actualTerm)
  ) %>%
    arrange(desc(numPaidOff))
predRet_Tst_linear_mode_lower_grades_outcome

sqrt( mean( (glm_lower_grade_testing- lcdfTst$actualReturn)^2) )
```

Lower Grade Model with RF
```{r}

rfModel_Ret_low_grade <- ranger(actualReturn ~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees =200,
importance='permutation')

rf_lower_grade_testing = predict(rfModel_Ret_low_grade, lcdfTst)

sqrt( mean((rf_lower_grade_testing$predictions - lcdfTst$actualReturn)^2) )

rf_lower_grades <- lcdfTst %>%
  select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
  mutate(predRet = rf_lower_grade_testing$predictions,
         tile = ntile(-predRet, 10))

rf_lower_grades_outcome <- rf_lower_grades %>%
  group_by(grade) %>%
  summarise(
    count = n(),
    avgpredRet = mean(predRet),
    numPaidOff = sum(loan_status == "Fully Paid"),
    numDefalted = sum(loan_status == "Charged Off"),
    avgActRet = mean(actualReturn),
    minRet = min(actualReturn),
    maxRet = max(actualReturn),
    avgTer = mean(actualTerm)
  ) %>%
    arrange(desc(numPaidOff))

rf_lower_grades_outcome
predRet_Tst_linear_mode_lower_grades_outcome

```

Combined RF Model for actual returns and loans 

```{r}

scoreTst_RF_Class <- predict(rfModel1_loan, data = lcdfTst, type = "response", probability = TRUE)

TRNPROP = 0.7  #proportion of examples in the training sample

nr<-nrow(lcdf2)
trnIndex<- sample(1:nr, size = round(TRNPROP * nr), replace=FALSE)

lcdfTrn <- lcdf2[trnIndex, ]
lcdfTst <- lcdf2[-trnIndex, ]

#actual return model 
rfModel_Ret <- ranger(actualReturn ~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees =200,
importance='permutation')

#loan status model 
rfModel1_loan <- ranger(loan_status ~., data=lcdfTrn %>%  select(-all_of(varsOmit)), num.trees = 200, importance='permutation', probability = TRUE)

combine_rt_return_pred = predict(rfModel_Ret,lcdfTst)
combine_loan_status_pred = predict(rfModel1_loan,lcdfTst)


combined_preds <- lcdfTst %>%
  select(loan_status, actualReturn, grade, int_rate, actualTerm) %>%
  mutate(
    prob_fully_paid = scoreTst_RF_Class$predictions[, "Fully Paid"],  
    predicted_return = combine_rt_return_pred$predictions,
    tile = ntile(combine_loan_status_pred$predictions, 10))
  )

Combined_Model_RF <- combined_preds %>%
  group_by(tile) %>%
  summarise(
    loanCount = n(),
    Fully_Paid_Prob = mean(prob_fully_paid),
    defaultRate = 1 - mean(prob_fully_paid),
    AvgPredReturn = mean(predicted_return),
    avgActRet = mean(actualReturn),
    minRet = min(actualReturn),
    maxRet = max(actualReturn),
    retSD = sd(actualReturn),
    avgTer = mean(actualTerm),
    investmentScore = mean(predicted_return * prob_fully_paid),
    totA = sum(grade == "A"),
    totB = sum(grade == "B"),
    totC = sum(grade == "C"),
    totD = sum(grade == "D"),
    totE = sum(grade == "E"),
    totF = sum(grade == "F")
  )

    
View(Combined_Model_RF)
```
